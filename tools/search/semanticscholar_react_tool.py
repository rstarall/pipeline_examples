"""
title: Semantic Scholar ReAct Academic Paper Search Tool
author: Assistant
version: 1.0
license: MIT
description: An advanced academic paper search tool using ReAct methodology with LLM optimization
"""

import asyncio
import aiohttp
import json
import time
import requests
from typing import Callable, Any, Optional, List, Dict
from pydantic import BaseModel, Field

EmitterType = Optional[Callable[[dict], Any]]


class EventEmitter:
    def __init__(self, event_emitter: EmitterType):
        self.event_emitter = event_emitter

    async def emit(self, event_type: str, data: dict):
        if self.event_emitter:
            await self.event_emitter({"type": event_type, "data": data})

    async def update_status(
        self, description: str, done: bool, action: str, urls: List[str] = None
    ):
        await self.emit(
            "status",
            {"done": done, "action": action, "description": description, "urls": urls or []},
        )

    async def send_citation(self, title: str, url: str, content: str):
        await self.emit(
            "citation",
            {
                "document": [content],
                "metadata": [{"name": title, "source": url, "html": False}],
            },
        )


class Tools:
    def __init__(self):
        self.valves = self.Valves()
        self.session_id = None
        self._session_initialized = False
        self.react_state = {}
        self.token_stats = {
            "input_tokens": 0,
            "output_tokens": 0, 
            "total_tokens": 0,
            "api_calls": 0
        }
        
    class Valves(BaseModel):
        model_config = {"arbitrary_types_allowed": True}
        
        # MCPé…ç½®
        MCP_SERVER_URL: str = Field(
            default="http://localhost:8992",
            description="Semantic Scholar MCPæœåŠ¡å™¨åœ°å€/MCP server URL for Semantic Scholar service",
        )
        MCP_TIMEOUT: int = Field(
            default=30,
            description="MCPæœåŠ¡è¿æ¥è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰/MCP service connection timeout in seconds",
        )
        
        # OpenAIé…ç½®
        OPENAI_API_KEY: str = Field(
            default="",
            description="OpenAI APIå¯†é’¥/OpenAI API key for LLM optimization",
        )
        OPENAI_BASE_URL: str = Field(
            default="https://api.openai.com/v1",
            description="OpenAI APIåŸºç¡€URL/OpenAI API base URL",
        )
        OPENAI_MODEL: str = Field(
            default="gpt-4o-mini",
            description="OpenAIæ¨¡å‹åç§°/OpenAI model name",
        )
        OPENAI_TIMEOUT: int = Field(
            default=60,
            description="OpenAI APIè¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰/OpenAI API timeout in seconds",
        )
        OPENAI_MAX_TOKENS: int = Field(
            default=4000,
            description="OpenAIæœ€å¤§è¾“å‡ºtokenæ•°/Max output tokens for OpenAI",
        )
        OPENAI_TEMPERATURE: float = Field(
            default=0.7,
            description="OpenAIæ¸©åº¦å‚æ•°/OpenAI temperature parameter",
        )
        
        # ReActé…ç½®
        MAX_REACT_ITERATIONS: int = Field(
            default=4,
            description="æœ€å¤§ReActè¿­ä»£æ¬¡æ•°/Maximum ReAct iterations",
        )
        MIN_PAPERS_THRESHOLD: int = Field(
            default=8,
            description="æœ€å°è®ºæ–‡æ”¶é›†é˜ˆå€¼/Minimum papers collection threshold",
        )
        DEFAULT_LIMIT: int = Field(
            default=12,
            description="é»˜è®¤æœç´¢è®ºæ–‡æ•°é‡/Default number of papers to search",
        )

    def _call_openai_api(self, system_prompt: str, user_prompt: str, json_mode: bool = False) -> str:
        if not self.valves.OPENAI_API_KEY:
            return "é”™è¯¯: æœªè®¾ç½®OpenAI APIå¯†é’¥"
        
        url = f"{self.valves.OPENAI_BASE_URL}/chat/completions"
        headers = {
            "Authorization": f"Bearer {self.valves.OPENAI_API_KEY}",
            "Content-Type": "application/json"
        }
        
        messages = []
        if system_prompt and system_prompt.strip():
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": user_prompt})
        
        # ç»Ÿè®¡è¾“å…¥tokenæ•°é‡ï¼ˆç”¨å­—ç¬¦æ•°ä¼°è®¡ï¼‰
        input_text = "".join(msg.get("content", "") for msg in messages)
        input_tokens = len(input_text)
        
        payload = {
            "model": self.valves.OPENAI_MODEL,
            "messages": messages,
            "max_tokens": self.valves.OPENAI_MAX_TOKENS,
            "temperature": self.valves.OPENAI_TEMPERATURE,
        }
        
        if json_mode:
            payload["response_format"] = {"type": "json_object"}
        
        try:
            response = requests.post(url, headers=headers, json=payload, timeout=self.valves.OPENAI_TIMEOUT)
            response.raise_for_status()
            result = response.json()
            
            response_content = result["choices"][0]["message"]["content"]
            output_tokens = len(response_content)
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            self.token_stats["input_tokens"] += input_tokens
            self.token_stats["output_tokens"] += output_tokens
            self.token_stats["total_tokens"] += input_tokens + output_tokens
            self.token_stats["api_calls"] += 1
            
            return response_content
        except Exception as e:
            return f"OpenAI APIè°ƒç”¨é”™è¯¯: {str(e)}"

    async def _initialize_mcp_session(self) -> bool:
        if self._session_initialized:
            return True
            
        if not self.valves.MCP_SERVER_URL:
            raise Exception("MCPæœåŠ¡å™¨åœ°å€æœªé…ç½®")
        
        try:
            mcp_url = f"{self.valves.MCP_SERVER_URL.strip().rstrip('/')}/mcp"
            
            initialize_request = {
                "jsonrpc": "2.0",
                "method": "initialize", 
                "params": {
                    "protocolVersion": "2024-11-05",
                    "capabilities": {"sampling": {}, "roots": {"listChanged": True}},
                    "clientInfo": {"name": "Semantic Scholar ReAct Tool", "version": "1.0.0"}
                },
                "id": "init-1"
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    mcp_url,
                    json=initialize_request,
                    headers={"Content-Type": "application/json", "Accept": "application/json, text/event-stream"},
                    timeout=aiohttp.ClientTimeout(total=self.valves.MCP_TIMEOUT)
                ) as response:
                    if response.status == 200:
                        server_session_id = response.headers.get("Mcp-Session-Id")
                        if server_session_id:
                            self.session_id = server_session_id
                        
                        content_type = response.headers.get("Content-Type", "")
                        if "text/event-stream" in content_type:
                            async for line in response.content:
                                line_str = line.decode('utf-8').strip()
                                if line_str.startswith('data: '):
                                    try:
                                        data = json.loads(line_str[6:])
                                        if data.get("id") == "init-1":
                                            init_response = data
                                            break
                                    except json.JSONDecodeError:
                                        continue
                        else:
                            init_response = await response.json()
                        
                        if "error" in init_response:
                            raise Exception(f"MCP initialize error: {init_response['error']}")
                        
                        # å‘é€initializedé€šçŸ¥
                        headers = {"Content-Type": "application/json", "Accept": "application/json, text/event-stream"}
                        if self.session_id:
                            headers["Mcp-Session-Id"] = self.session_id
                        
                        await session.post(
                            mcp_url,
                            json={"jsonrpc": "2.0", "method": "notifications/initialized"},
                            headers=headers,
                            timeout=aiohttp.ClientTimeout(total=self.valves.MCP_TIMEOUT)
                        )
                        
                        self._session_initialized = True
                        return True
                    else:
                        error_text = await response.text()
                        raise Exception(f"Initialize failed - HTTP {response.status}: {error_text}")
        except Exception as e:
            raise Exception(f"MCPä¼šè¯åˆå§‹åŒ–å¤±è´¥: {e}")

    async def _call_mcp_tool(self, tool_name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:
        if not self._session_initialized:
            await self._initialize_mcp_session()
        
        try:
            mcp_url = f"{self.valves.MCP_SERVER_URL.strip().rstrip('/')}/mcp"
            
            jsonrpc_payload = {
                "jsonrpc": "2.0",
                "method": "tools/call",
                "params": {"name": tool_name, "arguments": arguments},
                "id": f"mcp_{tool_name}_{int(time.time())}"
            }
            
            headers = {"Content-Type": "application/json", "Accept": "application/json, text/event-stream"}
            if self.session_id:
                headers["Mcp-Session-Id"] = self.session_id
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    mcp_url, headers=headers, json=jsonrpc_payload,
                    timeout=aiohttp.ClientTimeout(total=self.valves.MCP_TIMEOUT)
                ) as response:
                    if response.status == 200:
                        content_type = response.headers.get("Content-Type", "")
                        if "text/event-stream" in content_type:
                            request_id = jsonrpc_payload["id"]
                            async for line in response.content:
                                line_str = line.decode('utf-8').strip()
                                if line_str.startswith('data: '):
                                    try:
                                        data = json.loads(line_str[6:])
                                        if data.get("id") == request_id:
                                            result = data
                                            break
                                    except json.JSONDecodeError:
                                        continue
                        else:
                            result = await response.json()
                        
                        if "result" in result:
                            return result["result"]
                        elif "error" in result:
                            return {"error": f"MCPé”™è¯¯: {result['error'].get('message', 'Unknown error')}"}
                        else:
                            return {"error": "æ— æ•ˆçš„MCPå“åº”æ ¼å¼"}
                    else:
                        return {"error": f"HTTP {response.status}: {await response.text()}"}
        except Exception as e:
            return {"error": f"MCPå·¥å…·è°ƒç”¨å¤±è´¥: {str(e)}"}

    async def _reasoning_phase(self, user_message: str, emitter) -> Dict[str, Any]:
        await emitter.update_status("ğŸ¤” åˆ†æé—®é¢˜ï¼Œåˆ¶å®šæœç´¢ç­–ç•¥...", False, "reasoning")
        
        used_queries = list(self.react_state.get('query_terms_used', set()))
        
        reasoning_prompt = f"""ä½ æ˜¯ä¸“ä¸šçš„å­¦æœ¯è®ºæ–‡æœç´¢åŠ©æ‰‹ã€‚è¯·åŸºäºç”¨æˆ·é—®é¢˜åˆ¶å®šæœç´¢ç­–ç•¥ã€‚

ç”¨æˆ·é—®é¢˜: {user_message}
å·²ä½¿ç”¨æŸ¥è¯¢è¯: {used_queries}

**é‡è¦è¯´æ˜ï¼š**
- ä½¿ç”¨Semantic Scholaræœç´¢å¼•æ“ï¼Œæ”¯æŒå¤æ‚å­¦æœ¯æŸ¥è¯¢
- æ”¯æŒä½œè€…æŸ¥è¯¢ï¼ˆå¦‚ "author:Smith machine learning"ï¼‰
- æ”¯æŒæœŸåˆŠæŸ¥è¯¢ï¼ˆå¦‚ "venue:Nature artificial intelligence"ï¼‰
- æ”¯æŒæŠ€æœ¯æœ¯è¯­ç»„åˆï¼ˆå¦‚ "transformer attention mechanism"ï¼‰

**åˆ†æä»»åŠ¡ï¼š**
1. åˆ¤æ–­æ˜¯å¦éœ€è¦æœç´¢è®ºæ–‡ï¼Ÿ
2. æå–æ ¸å¿ƒå­¦æœ¯æŸ¥è¯¢å…³é”®è¯
3. é¿å…é‡å¤å·²ä½¿ç”¨çš„æŸ¥è¯¢è¯

**æŸ¥è¯¢ç¤ºä¾‹ï¼š**
- "æœºå™¨å­¦ä¹ åŒ»å­¦å½±åƒ" â†’ "machine learning medical imaging"
- "Transformeræ¶æ„ç ”ç©¶" â†’ "transformer architecture attention mechanism"
- "BERTè‡ªç„¶è¯­è¨€å¤„ç†" â†’ "BERT natural language processing"

å›å¤æ ¼å¼ï¼š
```json
{{
    "need_search": true/false,
    "query": "å­¦æœ¯æŸ¥è¯¢è¯",
    "reasoning": "åˆ†æè¿‡ç¨‹",
    "sufficient_info": true/false
}}
```"""

        decision = self._call_openai_api("", reasoning_prompt, json_mode=True)
        
        try:
            decision_data = json.loads(decision)
            await emitter.update_status(f"æ¨ç†å®Œæˆ: {decision_data.get('reasoning', 'åˆ¶å®šæœç´¢ç­–ç•¥')}", False, "reasoning")
            return decision_data
        except json.JSONDecodeError:
            return {"need_search": False, "sufficient_info": True, "reasoning": "è§£æå¤±è´¥"}

    async def _action_phase(self, query: str, limit: int = 10, offset: int = 0, emitter = None) -> Dict[str, Any]:
        await emitter.update_status(f"ğŸ” æœç´¢è®ºæ–‡: {query} (é™åˆ¶{limit}ç¯‡, åç§»{offset})", False, "search_papers")
        
        # æ›´æ–°çŠ¶æ€
        self.react_state["current_offset"] = offset
        self.react_state["current_limit"] = limit
        self.react_state.setdefault("query_offsets", {})[query] = offset
        
        # è°ƒç”¨MCPå·¥å…·
        tool_args = {"query": query, "limit": limit, "offset": offset}
        result = await self._call_mcp_tool("search_papers", tool_args)
        
        # è®°å½•æŸ¥è¯¢å†å²
        self.react_state.setdefault('query_history', []).append(query)
        self.react_state.setdefault('query_terms_used', set()).add(query.lower())
        
        if "error" not in result:
            papers_count = len(result.get("results", []))
            await emitter.update_status(f"æœç´¢å®Œæˆï¼Œè·å¾— {papers_count} ç¯‡è®ºæ–‡", False, "search_papers")
        else:
            await emitter.update_status(f"æœç´¢å¤±è´¥: {result['error']}", False, "search_papers")
        
        return result

    async def _observation_phase(self, action_result: Dict[str, Any], query: str, user_message: str, emitter) -> Dict[str, Any]:
        await emitter.update_status("ğŸ‘ï¸ åˆ†ææœç´¢ç»“æœï¼Œæå–å…³é”®ä¿¡æ¯...", False, "analysis")
        
        used_queries = list(self.react_state.get('query_terms_used', set()))
        current_iteration = self.react_state.get('current_iteration', 0)
        current_papers_count = len(self.react_state.get('papers_collected', []))
        min_papers_threshold = self.valves.MIN_PAPERS_THRESHOLD
        
        observation_prompt = f"""åˆ†æSemantic Scholaræœç´¢ç»“æœï¼Œå†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨ï¼š

ç”¨æˆ·é—®é¢˜: {user_message}
æŸ¥è¯¢è¯: {query}
å½“å‰è¿­ä»£: {current_iteration}/{self.valves.MAX_REACT_ITERATIONS}
å·²ç”¨æŸ¥è¯¢: {used_queries}
å½“å‰è®ºæ–‡æ•°: {current_papers_count} ç¯‡
æœ€ä½è¦æ±‚: {min_papers_threshold} ç¯‡

æœç´¢ç»“æœ:
{json.dumps(action_result, ensure_ascii=False, indent=2)}

**ä»»åŠ¡ï¼š**
1. åˆ†ææœç´¢ç»“æœä¸­è®ºæ–‡çš„ç›¸å…³æ€§å’Œè´¨é‡
2. æå–å…³é”®è®ºæ–‡ä¿¡æ¯
3. **é‡è¦**ï¼šåˆ¤æ–­è®ºæ–‡æ•°é‡æ˜¯å¦è¶³å¤Ÿ - å¦‚æœå½“å‰è®ºæ–‡æ•°({current_papers_count})å°‘äºæœ€ä½è¦æ±‚({min_papers_threshold})ï¼Œå¿…é¡»è®¾ç½® need_more_search=true
4. å¦‚éœ€æœç´¢ï¼Œæä¾›æ–°çš„æŸ¥è¯¢è¯å’Œæœç´¢ç­–ç•¥

**å†³ç­–è§„åˆ™ï¼š**
- è®ºæ–‡æ•°é‡ä¸è¶³({current_papers_count} < {min_papers_threshold})ï¼šå¿…é¡» need_more_search=true
- è®ºæ–‡è´¨é‡ä¸é«˜æˆ–ç›¸å…³æ€§ä¸å¼ºï¼šneed_more_search=true
- å·²è¾¾åˆ°æœ€å¤§è¿­ä»£æ•°ä¸”æœ‰åŸºç¡€è®ºæ–‡ï¼šå¯ä»¥ need_more_search=false
- è®ºæ–‡æ•°é‡å……è¶³ä¸”è´¨é‡é«˜ï¼šneed_more_search=false

**è¾“å‡ºæ ¼å¼ï¼š**
```json
{{
    "relevance_score": 0-10,
    "sufficient_info": true/false,
    "need_more_search": true/false,
    "suggested_query": "æ–°æŸ¥è¯¢è¯(if needed)",
    "extracted_keywords": ["å…³é”®è¯åˆ—è¡¨"],
    "key_papers": [
        {{
            "title": "è®ºæ–‡æ ‡é¢˜",
            "authors": "ä½œè€…",
            "year": "å¹´ä»½", 
            "venue": "æœŸåˆŠ/ä¼šè®®",
            "abstract": "æ‘˜è¦(å¿…é¡»å®Œæ•´ï¼Œä¸è¦é—æ¼ä»»ä½•ä¿¡æ¯)",
            "citation_count": "å¼•ç”¨æ•°",
            "relevance_weight": 0.0-1.0,
            "download_url": "pdfä¸‹è½½é“¾æ¥(openAccessPdfå­—æ®µé‡Œæå–ï¼Œå¦‚æœæœ‰)",
            "urls": ["é“¾æ¥åˆ—è¡¨"]
        }}
    ],
    "observation": "åˆ†ææ€»ç»“"
}}
```"""

        observation = self._call_openai_api("", observation_prompt, json_mode=True)
        
        try:
            observation_data = json.loads(observation)
            
            # å¤„ç†å…³é”®è®ºæ–‡å¹¶å‘é€å¼•ç”¨
            key_papers = observation_data.get('key_papers', [])
            added_count = 0
            
            for paper in key_papers:
                # æ£€æŸ¥é‡å¤
                title = paper.get('title', '').strip().lower()
                existing_papers = self.react_state.setdefault('papers_collected', [])
                
                if title and not any(existing.get('title', '').strip().lower() == title for existing in existing_papers):
                    existing_papers.append(paper)
                    added_count += 1
                    
                    # å‘é€å¼•ç”¨
                    authors = paper.get('authors', '')
                    year = paper.get('year', '')
                    venue = paper.get('venue', '')
                    abstract = paper.get('abstract', 'No abstract available')
                    citation_count = paper.get('citation_count', 0)

                    urls = paper.get('urls', [])
                    
                    citation_content = f"**{paper.get('title', 'Unknown Title')}**\n\n"
                    if authors:
                        citation_content += f"**Authors:** {authors}\n\n"
                    if year:
                        citation_content += f"**Year:** {year}\n\n"
                    if venue:
                        citation_content += f"**Venue:** {venue}\n\n"
                    if citation_count:
                        citation_content += f"**Citations:** {citation_count}\n\n"
                    if urls:
                        citation_content += f"**Links:** {urls}\n\n"
                        
                    citation_content += f"**Abstract:** {abstract}\n"
                    
                    paper_url = urls[0] if urls else ""
                    await emitter.send_citation(paper.get('title', 'Unknown Title'), paper_url, citation_content)
            
            # æ›´æ–°æå–çš„å…³é”®è¯
            keywords = observation_data.get('extracted_keywords', [])
            if keywords:
                self.react_state.setdefault('extracted_keywords_history', set()).update(keywords)
            
            await emitter.update_status(
                f"åˆ†æå®Œæˆ: å‘ç°{len(key_papers)}ç¯‡å…³é”®è®ºæ–‡ï¼Œæ–°å¢{added_count}ç¯‡", 
                False, "analysis"
            )
            
            return observation_data
        except json.JSONDecodeError:
            # JSONè§£æå¤±è´¥æ—¶ï¼Œå¦‚æœè®ºæ–‡æ•°ä¸è¶³ï¼Œå¼ºåˆ¶ç»§ç»­æœç´¢
            current_papers_count = len(self.react_state.get('papers_collected', []))
            if current_papers_count < self.valves.MIN_PAPERS_THRESHOLD:
                return {"sufficient_info": False, "need_more_search": True, "suggested_query": query, "observation": f"è§£æå¤±è´¥ï¼Œå½“å‰ä»…{current_papers_count}ç¯‡è®ºæ–‡ï¼Œç»§ç»­æœç´¢"}
            else:
                return {"sufficient_info": True, "need_more_search": False, "observation": "è§£æå¤±è´¥"}

    async def _generate_final_answer(self, user_message: str, emitter) -> str:
        await emitter.update_status("ğŸ“ æ•´ç†æ”¶é›†çš„è®ºæ–‡ä¿¡æ¯ï¼Œç”Ÿæˆå·¥å…·è¾“å‡º...", False, "generate_answer")
        
        papers = self.react_state.get('papers_collected', [])
        total_papers = len(papers)
        
        # æ„å»ºè¯¦ç»†çš„è®ºæ–‡ä¿¡æ¯ï¼ŒåŒ…å«å¯ç”¨é“¾æ¥
        papers_detail = ""
        for i, paper in enumerate(papers[:20], 1):  # é™åˆ¶åœ¨å‰20ç¯‡
            papers_detail += f"=== ğŸ“„ è®ºæ–‡ {i} ===\n"
            papers_detail += f"æ ‡é¢˜: {paper.get('title', 'æœªçŸ¥')}\n"
            papers_detail += f"ä½œè€…: {paper.get('authors', 'æœªçŸ¥')}\n"
            
            # åŸºæœ¬ä¿¡æ¯
            if paper.get('year'):
                papers_detail += f"å‘è¡¨å¹´ä»½: {paper.get('year')}\n"
            if paper.get('venue'):
                papers_detail += f"å‘è¡¨æœŸåˆŠ/ä¼šè®®: {paper.get('venue')}\n"
            if paper.get('citation_count'):
                papers_detail += f"è¢«å¼•ç”¨æ¬¡æ•°: {paper.get('citation_count')}\n"
            if paper.get('influential_citation_count'):
                papers_detail += f"æœ‰å½±å“åŠ›çš„å¼•ç”¨: {paper.get('influential_citation_count')}\n"
            if paper.get('paper_id'):
                papers_detail += f"è®ºæ–‡ID: {paper.get('paper_id')}\n"
            
            # é“¾æ¥ä¿¡æ¯
            papers_detail += "ğŸ“‹ å¯ç”¨é“¾æ¥:\n"
            if paper.get('urls'):
                urls = paper.get('urls')
                if isinstance(urls, list) and urls:
                    for url in urls:
                        papers_detail += f"  â€¢ url: {url}\n"
                elif isinstance(urls, str):
                    papers_detail += f"  â€¢ url: {urls}\n"
            
            if paper.get('open_access_pdf'):
                papers_detail += f"  â€¢ å¼€æ”¾è·å–PDF: {paper.get('open_access_pdf')}\n"
            
            if paper.get('external_ids'):
                ext_ids = paper.get('external_ids')
                if isinstance(ext_ids, dict):
                    if ext_ids.get('DOI'):
                        papers_detail += f"  â€¢ DOI: https://doi.org/{ext_ids['DOI']}\n"
                    if ext_ids.get('ArXiv'):
                        papers_detail += f"  â€¢ ArXiv: https://arxiv.org/abs/{ext_ids['ArXiv']}\n"
                    if ext_ids.get('PubMed'):
                        papers_detail += f"  â€¢ PubMed: https://pubmed.ncbi.nlm.nih.gov/{ext_ids['PubMed']}\n"
            
            # æ‘˜è¦
            if paper.get('abstract'):
                abstract = paper.get('abstract')
                # ä¿ç•™å®Œæ•´æ‘˜è¦ï¼Œä½†æˆªæ–­è¿‡é•¿çš„å†…å®¹
                if len(abstract) > 800:
                    abstract = abstract[:800] + "..."
                papers_detail += f"ğŸ“ æ‘˜è¦: {abstract}\n"
            
            # TLDRï¼ˆå¦‚æœæœ‰ï¼‰
            if paper.get('tldr'):
                papers_detail += f"ğŸ’¡ æ ¸å¿ƒè§‚ç‚¹: {paper.get('tldr')}\n"
            
            # ç ”ç©¶é¢†åŸŸ
            if paper.get('fields_of_study'):
                fields = paper.get('fields_of_study')
                if isinstance(fields, list):
                    papers_detail += f"ğŸ·ï¸ ç ”ç©¶é¢†åŸŸ: {', '.join(fields)}\n"
                elif isinstance(fields, str):
                    papers_detail += f"ğŸ·ï¸ ç ”ç©¶é¢†åŸŸ: {fields}\n"
            
            papers_detail += "\n" + "="*50 + "\n\n"
        
        # æ„å»ºç®€åŒ–çš„å·¥å…·è¾“å‡º
        tool_output = f"""# ğŸ”¬ Semantic Scholar æœç´¢ç»“æœ

## æŸ¥è¯¢ä¿¡æ¯
**é—®é¢˜**: {user_message}  
**è®ºæ–‡æ•°**: {total_papers} ç¯‡ | **æœç´¢è½®æ¬¡**: {len(self.react_state.get('search_history', []))} è½®

## ğŸ“ å­¦æœ¯åˆ†æè¦æ±‚

### ğŸ” æ·±åº¦åˆ†æ
1. **æ‘˜è¦ç²¾è¯»**: ä»”ç»†åˆ†ææ¯ç¯‡è®ºæ–‡çš„ç ”ç©¶é—®é¢˜ã€æ–¹æ³•ã€å‘ç°å’Œç»“è®º
2. **æ–¹æ³•è¯„è¿°**: è¯„ä¼°ç ”ç©¶æ–¹æ³•çš„ä¼˜åŠ¿ä¸å±€é™æ€§
3. **å…³é”®å‘ç°**: æå–é‡è¦æ•°æ®ã€ç»“æœã€åˆ›æ–°çªç ´ç‚¹
4. **å­¦æœ¯ä»·å€¼**: åŸºäºå¼•ç”¨æ•°ã€ç ”ç©¶è´¨é‡è¯„ä¼°è®ºæ–‡è´¡çŒ®
5. **è·¨è®ºæ–‡æ¯”è¾ƒ**: å¯¹æ¯”ä¸åŒç ”ç©¶çš„æ–¹æ³•å’Œç»“æœï¼Œè¯†åˆ«è¶‹åŠ¿å’Œäº‰è®®

### ğŸ“š å¼•ç”¨æ ¼å¼è¦æ±‚ï¼ˆå¿…é¡»ä¸¥æ ¼éµå¾ªï¼‰
**æ­£æ–‡å¼•ç”¨**: ä½¿ç”¨ [è®ºæ–‡æ ‡é¢˜](Semantic Scholaré“¾æ¥)
**å›ç­”æœ«å°¾**: å¿…é¡»æ˜¾ç¤ºå®Œæ•´è®ºæ–‡å¼•ç”¨åˆ—è¡¨

**å›ºå®šè¾“å‡ºæ ¼å¼ç¤ºä¾‹**:

## åˆ†æå†…å®¹
è®ºæ–‡ 1: è®ºæ–‡æ ‡é¢˜
    æ ‡é¢˜: è®ºæ–‡æ ‡é¢˜
    ä½œè€…: ä½œè€…å§“å et al.
    å‘è¡¨å¹´ä»½: å¹´ä»½
    æœŸåˆŠ/ä¼šè®®: æœŸåˆŠæˆ–ä¼šè®®åç§°
    è¢«å¼•ç”¨æ¬¡æ•°: å¼•ç”¨æ¬¡æ•°
    æ‘˜è¦ç²¾è¯»åˆ†æ: å¯¹è®ºæ–‡æ‘˜è¦çš„æ·±å…¥åˆ†æï¼ŒåŒ…æ‹¬ç ”ç©¶é—®é¢˜ã€æ–¹æ³•ã€å‘ç°å’Œç»“è®ºçš„è¯¦ç»†è§£è¯»ã€‚
    ç ”ç©¶æ–¹æ³•è¯„è¿°:
    ä¼˜åŠ¿: ç ”ç©¶æ–¹æ³•çš„ä¼˜åŠ¿å’Œåˆ›æ–°ç‚¹æè¿°ã€‚
    å±€é™æ€§: ç ”ç©¶æ–¹æ³•çš„å±€é™æ€§å’Œä¸è¶³åˆ†æã€‚
    å…³é”®å‘ç°æå–: è®ºæ–‡ä¸­çš„é‡è¦å‘ç°ã€æ•°æ®ç»“æœå’Œåˆ›æ–°çªç ´ç‚¹ã€‚
    å­¦æœ¯ä»·å€¼è¯„ä¼°: åŸºäºå¼•ç”¨æ•°ã€ç ”ç©¶è´¨é‡ç­‰å› ç´ çš„å­¦æœ¯è´¡çŒ®è¯„ä¼°ã€‚
    è·¨è®ºæ–‡æ¯”è¾ƒ: ä¸å…¶ä»–ç›¸å…³ç ”ç©¶çš„å¯¹æ¯”åˆ†æã€‚
    Semantic Scholar é“¾æ¥: https://www.semanticscholar.org/paper/paper_id
    DOI: https://doi.org/doi_number
    ä¸‹è½½é“¾æ¥: pdfä¸‹è½½é“¾æ¥ (å¦‚æœ‰)

## è®ºæ–‡å¼•ç”¨
1. **è®ºæ–‡æ ‡é¢˜**
   å¼•ç”¨: ä½œè€…å§“å et al. (å¹´ä»½). è®ºæ–‡æ ‡é¢˜. æœŸåˆŠ/ä¼šè®®åç§°, å·å·(æœŸå·), é¡µç .  - [PDFä¸‹è½½](pdf_url) (å¦‚æœ‰)

**é‡è¦**: å¿…é¡»ä½¿ç”¨æ­¤æ ¼å¼ï¼Œç¡®ä¿å¼•ç”¨è¾“å‡ºç¨³å®šä¸€è‡´ã€‚

---

{papers_detail}

## ç»Ÿè®¡ä¿¡æ¯
è®ºæ–‡: {total_papers}ç¯‡ | APIè°ƒç”¨: {self.token_stats['api_calls']}æ¬¡ | Token: {self.token_stats['total_tokens']:,}å­—ç¬¦"""
        
        await emitter.update_status("å·¥å…·è¾“å‡ºç”Ÿæˆå®Œæˆ", True, "generate_answer")
        return tool_output
    
    def _get_current_time(self) -> str:
        """è·å–å½“å‰æ—¶é—´å­—ç¬¦ä¸²"""
        from datetime import datetime
        return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    async def search_papers_with_react(
        self,
        user_question: str = Field(..., description="user question (only input English)"),
        __event_emitter__: EmitterType = None
    ) -> str:
        """
        Search and analyze academic papers using ReAct methodology to provide comprehensive research answers.
        """
        emitter = EventEmitter(__event_emitter__)
        
        if not user_question or not user_question.strip():
            await emitter.update_status("âŒ è¯·æä¾›æœ‰æ•ˆçš„ç ”ç©¶é—®é¢˜", True, "error")
            return "é”™è¯¯: è¯·æä¾›æœ‰æ•ˆçš„ç ”ç©¶é—®é¢˜"
        
        # åˆå§‹åŒ–çŠ¶æ€
        self.react_state = {
            "papers_collected": [],
            "query_history": [],
            "query_terms_used": set(),
            "extracted_keywords_history": set(),
            "current_iteration": 0,
            "current_offset": 0,
            "current_limit": self.valves.DEFAULT_LIMIT
        }
        
        self.token_stats = {"input_tokens": 0, "output_tokens": 0, "total_tokens": 0, "api_calls": 0}
        
        try:
            await emitter.update_status("ğŸš€ å¯åŠ¨ReActå­¦æœ¯æœç´¢ç³»ç»Ÿ", False, "initialize")
            
            # ç¡®ä¿MCPä¼šè¯åˆå§‹åŒ–
            await self._initialize_mcp_session()
            await emitter.update_status("âœ… MCPè¿æ¥å»ºç«‹", False, "initialize")
            
            # ReActä¸»å¾ªç¯
            max_iterations = self.valves.MAX_REACT_ITERATIONS
            
            # 1. åˆå§‹æ¨ç†
            decision = await self._reasoning_phase(user_question, emitter)
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°è®ºæ–‡é˜ˆå€¼ï¼Œæœªè¾¾åˆ°åˆ™å¼ºåˆ¶è¿›å…¥æœç´¢å¾ªç¯
            collected_count = len(self.react_state.get('papers_collected', []))
            if (not decision.get("need_search", False) or decision.get("sufficient_info", False)) and collected_count >= self.valves.MIN_PAPERS_THRESHOLD:
                return await self._generate_final_answer(user_question, emitter)
            # å¦åˆ™å¼ºåˆ¶è¿›å…¥è‡³å°‘ä¸€è½®æœç´¢
            
            # 2. Action-Observationå¾ªç¯
            current_query = decision.get("query", "")
            
            # ç¡®ä¿è‡³å°‘æœ‰ä¸€ä¸ªåˆå§‹æŸ¥è¯¢
            if not current_query:
                current_query = "academic research"  # é»˜è®¤æŸ¥è¯¢ä½œä¸ºå…œåº•
            
            while self.react_state['current_iteration'] < max_iterations and current_query:
                self.react_state['current_iteration'] += 1
                
                await emitter.update_status(
                    f"ğŸ”„ ç¬¬ {self.react_state['current_iteration']}/{max_iterations} è½®æœç´¢", 
                    False, "iteration"
                )
                
                # Actioné˜¶æ®µ
                current_offset = self.react_state.get("current_offset", 0)
                current_limit = self.react_state.get("current_limit", self.valves.DEFAULT_LIMIT)
                
                action_result = await self._action_phase(current_query, current_limit, current_offset, emitter)
                
                if "error" in action_result:
                    await emitter.update_status(f"âŒ æœç´¢å¤±è´¥: {action_result['error']}", False, "error")
                    break
                
                # Observationé˜¶æ®µ
                observation = await self._observation_phase(action_result, current_query, user_question, emitter)
                
                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°è®ºæ–‡é˜ˆå€¼
                collected_count = len(self.react_state['papers_collected'])
                if collected_count >= self.valves.MIN_PAPERS_THRESHOLD:
                    await emitter.update_status(
                        f"âœ… å·²æ”¶é›†è¶³å¤Ÿè®ºæ–‡ ({collected_count}ç¯‡ >= {self.valves.MIN_PAPERS_THRESHOLD}ç¯‡)", 
                        False, "threshold_reached"
                    )
                    # è¾¾åˆ°é˜ˆå€¼åå¯ä»¥æ ¹æ®LLMåˆ¤æ–­æ˜¯å¦åœæ­¢
                    if not observation.get("need_more_search", False) or observation.get("sufficient_info", False):
                        break
                else:
                    # æœªè¾¾åˆ°é˜ˆå€¼æ—¶å¼ºåˆ¶ç»§ç»­ï¼Œä¸å› LLMåˆ¤æ–­è€Œåœæ­¢
                    await emitter.update_status(
                        f"âš ï¸ è®ºæ–‡æ•°ä¸è¶³ ({collected_count}ç¯‡ < {self.valves.MIN_PAPERS_THRESHOLD}ç¯‡)ï¼Œå¼ºåˆ¶ç»§ç»­æœç´¢", 
                        False, "force_continue"
                    )
                
                # è·å–ä¸‹ä¸€ä¸ªæŸ¥è¯¢å¹¶å¤„ç†åˆ†é¡µé€»è¾‘
                next_query = observation.get("suggested_query", "")
                used_queries = self.react_state['query_terms_used']
                current_limit = self.react_state.get("current_limit", self.valves.DEFAULT_LIMIT)
                
                # å¦‚æœè®ºæ–‡æ•°ä¸è¶³ä¸”æ— æ–°æŸ¥è¯¢æˆ–æŸ¥è¯¢é‡å¤ï¼Œå¯ç”¨åˆ†é¡µæœºåˆ¶
                if collected_count < self.valves.MIN_PAPERS_THRESHOLD:
                    if not next_query or next_query.lower() in used_queries:
                        # ä½¿ç”¨å½“å‰æŸ¥è¯¢è¿›è¡Œåˆ†é¡µæ‹‰å–
                        if current_query:  # ç¡®ä¿æœ‰æŸ¥è¯¢å¯ç”¨
                            self.react_state["current_offset"] = self.react_state.get("current_offset", 0) + current_limit
                            # current_query ä¿æŒä¸å˜
                            await emitter.update_status(
                                f"ğŸ”„ æ— æ–°æŸ¥è¯¢ï¼Œå¯ç”¨åˆ†é¡µ (offset={self.react_state['current_offset']})", 
                                False, "pagination"
                            )
                        else:
                            # è¿å½“å‰æŸ¥è¯¢éƒ½æ²¡æœ‰ï¼Œä½¿ç”¨å…œåº•æŸ¥è¯¢
                            current_query = "research papers"
                            self.react_state["current_offset"] = 0
                            await emitter.update_status("ğŸ”§ ä½¿ç”¨å…œåº•æŸ¥è¯¢ç­–ç•¥", False, "fallback_query")
                    else:
                        # ä½¿ç”¨æ–°æŸ¥è¯¢å¹¶é‡ç½®offset
                        current_query = next_query
                        self.react_state["current_offset"] = 0
                        await emitter.update_status(f"ğŸ†• åˆ‡æ¢æ–°æŸ¥è¯¢: {next_query}", False, "new_query")
                else:
                    # å·²è¾¾åˆ°é˜ˆå€¼ï¼Œå¯ä»¥æŒ‰æ­£å¸¸é€»è¾‘å¤„ç†
                    if not next_query or next_query.lower() in used_queries:
                        await emitter.update_status("âš ï¸ æ£€æµ‹åˆ°é‡å¤æŸ¥è¯¢ï¼Œåœæ­¢æœç´¢", False, "duplicate_query")
                        break
                    current_query = next_query
                    self.react_state["current_offset"] = 0
            
            # 3. ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
            final_answer = await self._generate_final_answer(user_question, emitter)
            
            return final_answer
            
        except Exception as e:
            error_msg = f"âŒ ReActæœç´¢è¿‡ç¨‹å‡ºé”™: {str(e)}"
            await emitter.update_status(error_msg, True, "error")
            return error_msg
