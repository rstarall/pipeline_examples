"""
PubChemPy MCP Pipeline V2 - åŸºäºMCPåè®®çš„åŒ–å­¦ä¿¡æ¯æŸ¥è¯¢ç®¡é“

åŠŸèƒ½ç‰¹æ€§:
1. é€šè¿‡MCP JSON-RPCåè®®çš„tools/listæ–¹æ³•åŠ¨æ€å‘ç°å·¥å…·ï¼Œæ ¹æ®tagè¿›è¡Œè¿‡æ»¤
2. ä½¿ç”¨MCP JSON-RPCåè®®è¿›è¡Œå·¥å…·è°ƒç”¨
3. æ”¯æŒæµå¼è¾“å‡ºå’Œå¤šè½®å·¥å…·è°ƒç”¨
4. æ™ºèƒ½å·¥å…·é€‰æ‹©å’Œå‚æ•°ç”Ÿæˆ
"""

import os
import json
import requests
import asyncio
import aiohttp
import time
from typing import List, Union, Generator, Iterator, Dict, Any, Optional, AsyncGenerator
from pydantic import BaseModel
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åç«¯é˜¶æ®µæ ‡é¢˜æ˜ å°„
STAGE_TITLES = {
    "mcp_discovery": "MCPæœåŠ¡å‘ç°", 
    "tool_calling": "å·¥å…·è°ƒç”¨",
    "answer_generation": "ç”Ÿæˆå›ç­”",
}

STAGE_GROUP = {
    "mcp_discovery": "stage_group_1",
    "tool_calling": "stage_group_2", 
    "answer_generation": "stage_group_3",
}

class Pipeline:
    class Valves(BaseModel):
        # OpenAIé…ç½®
        OPENAI_API_KEY: str
        OPENAI_BASE_URL: str
        OPENAI_MODEL: str
        OPENAI_TIMEOUT: int
        OPENAI_MAX_TOKENS: int
        OPENAI_TEMPERATURE: float
        
        # Pipelineé…ç½®
        ENABLE_STREAMING: bool
        DEBUG_MODE: bool
        MAX_TOOL_CALLS: int
        
        # MCPé…ç½®
        MCP_SERVER_URL: str
        MCP_TAG: str
        MCP_TIMEOUT: int

    def __init__(self):
        self.name = "PubChemPy MCP Chemical Pipeline V2"
        
        # åˆå§‹åŒ–tokenç»Ÿè®¡
        self.token_stats = {
            "input_tokens": 0, 
            "output_tokens": 0,
            "total_tokens": 0
        }
        
        # MCPå·¥å…·ç¼“å­˜
        self.mcp_tools = {}
        self.tools_loaded = False
        
        # MCPä¼šè¯IDå°†åœ¨åˆå§‹åŒ–æ—¶ä»æœåŠ¡å™¨è·å–
        self.session_id = None
        
        self.valves = self.Valves(
            **{
                # OpenAIé…ç½®
                "OPENAI_API_KEY": os.getenv("OPENAI_API_KEY", ""),
                "OPENAI_BASE_URL": os.getenv("OPENAI_BASE_URL", "https://openrouter.ai/api/v1"),
                "OPENAI_MODEL": os.getenv("OPENAI_MODEL", "gpt-4o"),
                "OPENAI_TIMEOUT": int(os.getenv("OPENAI_TIMEOUT", "60")),
                "OPENAI_MAX_TOKENS": int(os.getenv("OPENAI_MAX_TOKENS", "4000")),
                "OPENAI_TEMPERATURE": float(os.getenv("OPENAI_TEMPERATURE", "0.7")),
                
                # Pipelineé…ç½®
                "ENABLE_STREAMING": os.getenv("ENABLE_STREAMING", "true").lower() == "true",
                "DEBUG_MODE": os.getenv("DEBUG_MODE", "false").lower() == "true",
                "MAX_TOOL_CALLS": int(os.getenv("MAX_TOOL_CALLS", "5")),
                
                # MCPé…ç½®
                "MCP_SERVER_URL": os.getenv("MCP_SERVER_URL", "http://localhost:8989"),
                "MCP_TAG": os.getenv("MCP_TAG", "search"),
                "MCP_TIMEOUT": int(os.getenv("MCP_TIMEOUT", "30")),
            }
        )

    async def on_startup(self):
        print(f"PubChemPy MCP Chemical Pipeline V2å¯åŠ¨: {__name__}")
        
        # éªŒè¯å¿…éœ€çš„APIå¯†é’¥
        if not self.valves.OPENAI_API_KEY:
            print("âŒ ç¼ºå°‘OpenAI APIå¯†é’¥ï¼Œè¯·è®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
        
        # éªŒè¯MCPæœåŠ¡å™¨åœ°å€
        print(f"ğŸ”— MCPæœåŠ¡å™¨åœ°å€: {self.valves.MCP_SERVER_URL}")
        print(f"ğŸ·ï¸ MCPæ ‡ç­¾: {self.valves.MCP_TAG}")
        if not self.valves.MCP_SERVER_URL:
            print("âŒ ç¼ºå°‘MCPæœåŠ¡å™¨åœ°å€ï¼Œè¯·è®¾ç½®MCP_SERVER_URLç¯å¢ƒå˜é‡")
        
        # å‘ç°MCPå·¥å…·
        try:
            await self._discover_mcp_tools()
            print(f"âœ… æˆåŠŸå‘ç° {len(self.mcp_tools)} ä¸ªMCPå·¥å…·")
        except Exception as e:
            print(f"âŒ MCPå·¥å…·å‘ç°å¤±è´¥: {e}")

    async def on_shutdown(self):
        print(f"PubChemPy MCP Chemical Pipeline V2å…³é—­: {__name__}")
        print("ğŸ”š Pipelineå·²å…³é—­")

    async def _initialize_mcp_session(self):
        """åˆå§‹åŒ–MCPä¼šè¯å¹¶è·å–æœåŠ¡å™¨åˆ†é…çš„session ID"""
        if not self.valves.MCP_SERVER_URL:
            raise Exception("MCPæœåŠ¡å™¨åœ°å€æœªé…ç½®")
        
        try:
            mcp_url = f"{self.valves.MCP_SERVER_URL.strip().rstrip('/')}/mcp"
            
            # Step 1: å‘é€initializeè¯·æ±‚ï¼ˆä¸å¸¦session IDï¼‰
            initialize_request = {
                "jsonrpc": "2.0",
                "method": "initialize",
                "params": {
                    "protocolVersion": "2024-11-05",
                    "capabilities": {
                        "sampling": {},
                        "roots": {"listChanged": True}
                    },
                    "clientInfo": {
                        "name": "PubChemPy MCP Pipeline",
                        "version": "2.0.0"
                    }
                },
                "id": "init-1"
            }
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    mcp_url,
                    json=initialize_request,
                    headers={
                        "Content-Type": "application/json",
                        "Accept": "application/json, text/event-stream"
                    },
                    timeout=aiohttp.ClientTimeout(total=self.valves.MCP_TIMEOUT)
                ) as response:
                    if response.status == 200:
                        # æ£€æŸ¥å“åº”å¤´ä¸­çš„session ID
                        server_session_id = response.headers.get("Mcp-Session-Id")
                        if server_session_id:
                            self.session_id = server_session_id
                            logger.info(f"Got session ID from server: {self.session_id}")
                        
                        # å¤„ç†å“åº”ï¼Œå¯èƒ½æ˜¯JSONæˆ–SSEæµ
                        content_type = response.headers.get("Content-Type", "")
                        if "text/event-stream" in content_type:
                            # å¤„ç†SSEæµ
                            init_response = None
                            async for line in response.content:
                                line_str = line.decode('utf-8').strip()
                                if line_str.startswith('data: '):
                                    try:
                                        data = json.loads(line_str[6:])  # ç§»é™¤ 'data: ' å‰ç¼€
                                        if data.get("id") == "init-1":  # åŒ¹é…æˆ‘ä»¬çš„è¯·æ±‚ID
                                            init_response = data
                                            break
                                    except json.JSONDecodeError:
                                        continue
                        else:
                            # ç›´æ¥JSONå“åº”
                            init_response = await response.json()
                        
                        if not init_response:
                            raise Exception("No initialize response received")
                        
                        if "error" in init_response:
                            raise Exception(f"MCP initialize error: {init_response['error']}")
                        
                        # Step 2: å‘é€initializedé€šçŸ¥
                        initialized_notification = {
                            "jsonrpc": "2.0",
                            "method": "notifications/initialized"
                        }
                        
                        headers = {
                            "Content-Type": "application/json",
                            "Accept": "application/json, text/event-stream"
                        }
                        if hasattr(self, 'session_id') and self.session_id:
                            headers["Mcp-Session-Id"] = self.session_id
                        
                        async with session.post(
                            mcp_url,
                            json=initialized_notification,
                            headers=headers,
                            timeout=aiohttp.ClientTimeout(total=self.valves.MCP_TIMEOUT)
                        ) as notify_response:
                            if notify_response.status not in [200, 202]:
                                logger.warning(f"Initialized notification failed: {notify_response.status}")
                        
                        logger.info("MCP session initialized successfully")
                    else:
                        error_text = await response.text()
                        raise Exception(f"Initialize failed - HTTP {response.status}: {error_text}")
                        
        except Exception as e:
            logger.error(f"MCP session initialization failed: {e}")
            raise

    async def _discover_mcp_tools(self):
        """é€šè¿‡MCP JSON-RPCåè®®å‘ç°æœåŠ¡å™¨å·¥å…·"""
        if not self.valves.MCP_SERVER_URL:
            raise Exception("MCPæœåŠ¡å™¨åœ°å€æœªé…ç½®")
        
        # é¦–å…ˆåˆå§‹åŒ–MCPä¼šè¯
        if not hasattr(self, '_session_initialized'):
            await self._initialize_mcp_session()
            self._session_initialized = True
        
        try:
            # æ„å»ºMCP JSON-RPCè¯·æ±‚
            mcp_request = {
                "jsonrpc": "2.0",
                "method": "tools/list",
                "id": "tools-list-1"
            }
            
            mcp_url = f"{self.valves.MCP_SERVER_URL.strip().rstrip('/')}/mcp"
            
            headers = {
                "Content-Type": "application/json",
                "Accept": "application/json, text/event-stream"
            }
            if hasattr(self, 'session_id') and self.session_id:
                headers["Mcp-Session-Id"] = self.session_id
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    mcp_url,
                    json=mcp_request,
                    headers=headers,
                    timeout=aiohttp.ClientTimeout(total=self.valves.MCP_TIMEOUT)
                ) as response:
                    if response.status == 200:
                        # å¤„ç†å“åº”ï¼Œå¯èƒ½æ˜¯JSONæˆ–SSEæµ
                        content_type = response.headers.get("Content-Type", "")
                        if "text/event-stream" in content_type:
                            # å¤„ç†SSEæµ
                            mcp_response = None
                            async for line in response.content:
                                line_str = line.decode('utf-8').strip()
                                if line_str.startswith('data: '):
                                    try:
                                        data = json.loads(line_str[6:])  # ç§»é™¤ 'data: ' å‰ç¼€
                                        if data.get("id") == "tools-list-1":  # åŒ¹é…æˆ‘ä»¬çš„è¯·æ±‚ID
                                            mcp_response = data
                                            break
                                    except json.JSONDecodeError:
                                        continue
                        else:
                            # ç›´æ¥JSONå“åº”
                            mcp_response = await response.json()
                        
                        if not mcp_response:
                            raise Exception("No tools/list response received")
                        
                        if "error" in mcp_response:
                            raise Exception(f"MCP error: {mcp_response['error']}")
                        
                        tools = mcp_response.get("result", {}).get("tools", [])
                        
                        # æ ¹æ®tagè¿‡æ»¤å·¥å…·å¹¶è§£æå·¥å…·ä¿¡æ¯
                        for tool in tools:
                            tool_tags = tool.get("tags", [])
                            # åªåŠ è½½åŒ¹é…æŒ‡å®štagçš„å·¥å…·
                            if self.valves.MCP_TAG in tool_tags:
                                tool_name = tool.get("name")
                                if tool_name:
                                    self.mcp_tools[tool_name] = {
                                        "name": tool_name,
                                        "description": tool.get("description", ""),
                                        "input_schema": tool.get("inputSchema", {}),
                                        "tags": tool_tags
                                    }
                        
                        self.tools_loaded = True
                        logger.info(f"Successfully discovered {len(self.mcp_tools)} MCP tools with tag '{self.valves.MCP_TAG}'")
                    else:
                        error_text = await response.text()
                        raise Exception(f"HTTP {response.status}: {error_text}")
                        
        except Exception as e:
            logger.error(f"MCP tool discovery failed: {e}")
            raise



    async def _call_mcp_tool(self, tool_name: str, arguments: Dict[str, Any]) -> Dict[str, Any]:
        """ä½¿ç”¨MCP JSON-RPCåè®®è°ƒç”¨å·¥å…·"""
        if not self.valves.MCP_SERVER_URL:
            return {"error": "MCPæœåŠ¡å™¨åœ°å€æœªé…ç½®"}
        
        if not self.tools_loaded:
            try:
                await self._discover_mcp_tools()
            except Exception as e:
                return {"error": f"å·¥å…·å‘ç°å¤±è´¥: {str(e)}"}
        
        if tool_name not in self.mcp_tools:
            return {"error": f"å·¥å…· '{tool_name}' ä¸å¯ç”¨"}
        
        try:
            # æ„å»ºMCP JSON-RPCè¯·æ±‚
            mcp_url = f"{self.valves.MCP_SERVER_URL.strip().rstrip('/')}/mcp"
            
            # MCP JSON-RPCæ ¼å¼è¯·æ±‚ä½“
            jsonrpc_payload = {
                "jsonrpc": "2.0",
                "method": "tools/call",
                "params": {
                    "name": tool_name,
                    "arguments": arguments
                },
                "id": f"mcp_{tool_name}_{int(time.time())}"
            }
            
            headers = {
                "Content-Type": "application/json",
                "Accept": "application/json, text/event-stream"
            }
            if hasattr(self, 'session_id') and self.session_id:
                headers["Mcp-Session-Id"] = self.session_id
            
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    mcp_url,
                    headers=headers,
                    json=jsonrpc_payload,
                    timeout=aiohttp.ClientTimeout(total=self.valves.MCP_TIMEOUT)
                ) as response:
                    if response.status == 200:
                        # å¤„ç†å“åº”ï¼Œå¯èƒ½æ˜¯JSONæˆ–SSEæµ
                        content_type = response.headers.get("Content-Type", "")
                        if "text/event-stream" in content_type:
                            # å¤„ç†SSEæµ
                            result = None
                            request_id = jsonrpc_payload["id"]
                            async for line in response.content:
                                line_str = line.decode('utf-8').strip()
                                if line_str.startswith('data: '):
                                    try:
                                        data = json.loads(line_str[6:])  # ç§»é™¤ 'data: ' å‰ç¼€
                                        if data.get("id") == request_id:  # åŒ¹é…æˆ‘ä»¬çš„è¯·æ±‚ID
                                            result = data
                                            break
                                    except json.JSONDecodeError:
                                        continue
                        else:
                            # ç›´æ¥JSONå“åº”
                            result = await response.json()
                        
                        if not result:
                            return {"error": "No response received"}
                        
                        # å¤„ç†MCP JSON-RPCå“åº”
                        if "result" in result:
                            return result["result"]
                        elif "error" in result:
                            return {"error": f"MCPé”™è¯¯: {result['error'].get('message', 'Unknown error')}"}
                        else:
                            return {"error": "æ— æ•ˆçš„MCPå“åº”æ ¼å¼"}
                    else:
                        return {"error": f"HTTP {response.status}: {await response.text()}"}
                        
        except asyncio.TimeoutError:
            logger.error(f"MCPå·¥å…·è°ƒç”¨è¶…æ—¶: {tool_name}")
            return {"error": "è¯·æ±‚è¶…æ—¶"}
        except aiohttp.ClientError as e:
            logger.error(f"MCP HTTPè¯·æ±‚å¤±è´¥: {e}")
            return {"error": f"HTTPè¯·æ±‚å¤±è´¥: {str(e)}"}
        except Exception as e:
            logger.error(f"MCPå·¥å…·è°ƒç”¨å¤±è´¥: {e}")
            return {"error": str(e)}

    async def _execute_mcp_tool(self, tool_name: str, arguments: Dict[str, Any]) -> str:
        """æ‰§è¡ŒMCPå·¥å…·å¹¶è¿”å›æ ¼å¼åŒ–ç»“æœ"""
        result = await self._call_mcp_tool(tool_name, arguments)
        
        if "content" in result and result["content"]:
            # æå–æ–‡æœ¬å†…å®¹
            text_content = ""
            for content in result["content"]:
                if content.get("type") == "text":
                    text_content += content.get("text", "") + "\n"
            return text_content.strip()
        elif "error" in result:
            return f"å·¥å…·æ‰§è¡Œå¤±è´¥: {result['error']}"
        else:
            return "å·¥å…·æ‰§è¡Œæœªè¿”å›æœ‰æ•ˆç»“æœ"

    def _estimate_tokens(self, text: str) -> int:
        """ç®€å•çš„tokenä¼°ç®—å‡½æ•°"""
        if not text:
            return 0
        chinese_chars = sum(1 for char in text if '\u4e00' <= char <= '\u9fff')
        english_text = ''.join(char if not ('\u4e00' <= char <= '\u9fff') else ' ' for char in text)
        english_words = len([word for word in english_text.split() if word.strip()])
        estimated_tokens = chinese_chars + int(english_words * 1.3)
        return max(estimated_tokens, 1)

    def _add_input_tokens(self, text: str):
        """æ·»åŠ è¾“å…¥tokenç»Ÿè®¡"""
        tokens = self._estimate_tokens(text)
        self.token_stats["input_tokens"] += tokens
        self.token_stats["total_tokens"] += tokens

    def _add_output_tokens(self, text: str):
        """æ·»åŠ è¾“å‡ºtokenç»Ÿè®¡"""
        tokens = self._estimate_tokens(text)
        self.token_stats["output_tokens"] += tokens
        self.token_stats["total_tokens"] += tokens

    def _reset_token_stats(self):
        """é‡ç½®tokenç»Ÿè®¡"""
        self.token_stats = {
            "input_tokens": 0,
            "output_tokens": 0,
            "total_tokens": 0
        }

    def _get_token_stats(self) -> dict:
        """è·å–tokenç»Ÿè®¡ä¿¡æ¯"""
        return self.token_stats.copy()

    def _call_openai_api(self, system_prompt: str, user_prompt: str, json_mode: bool = False) -> str:
        """è°ƒç”¨OpenAI API"""
        if not self.valves.OPENAI_API_KEY:
            return "é”™è¯¯: æœªè®¾ç½®OpenAI APIå¯†é’¥"
        
        url = f"{self.valves.OPENAI_BASE_URL}/chat/completions"
        
        headers = {
            "Authorization": f"Bearer {self.valves.OPENAI_API_KEY}",
            "Content-Type": "application/json"
        }
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨ï¼Œåªæœ‰system_promptä¸ä¸ºç©ºæ—¶æ‰æ·»åŠ systemæ¶ˆæ¯
        messages = []
        if system_prompt and system_prompt.strip():
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": user_prompt})
        
        payload = {
            "model": self.valves.OPENAI_MODEL,
            "messages": messages,
            "max_tokens": self.valves.OPENAI_MAX_TOKENS,
            "temperature": self.valves.OPENAI_TEMPERATURE,
        }
        
        if json_mode:
            payload["response_format"] = {"type": "json_object"}
        
        # æ·»åŠ è¾“å…¥tokenç»Ÿè®¡
        if system_prompt and system_prompt.strip():
            self._add_input_tokens(system_prompt)
        self._add_input_tokens(user_prompt)
        
        try:
            response = requests.post(
                url,
                headers=headers,
                json=payload,
                timeout=self.valves.OPENAI_TIMEOUT
            )
            response.raise_for_status()
            result = response.json()
            
            answer = result["choices"][0]["message"]["content"]
            self._add_output_tokens(answer)
            
            return answer
            
        except Exception as e:
            error_msg = f"OpenAI APIè°ƒç”¨é”™è¯¯: {str(e)}"
            if self.valves.DEBUG_MODE:
                print(f"âŒ {error_msg}")
            return error_msg

    def _stream_openai_response(self, user_prompt: str, system_prompt: str) -> Generator:
        """æµå¼å¤„ç†OpenAIå“åº”"""
        if not self.valves.OPENAI_API_KEY:
            yield "é”™è¯¯: æœªè®¾ç½®OpenAI APIå¯†é’¥"
            return
        
        url = f"{self.valves.OPENAI_BASE_URL}/chat/completions"
        
        headers = {
            "Authorization": f"Bearer {self.valves.OPENAI_API_KEY}",
            "Content-Type": "application/json"
        }
        
        # æ„å»ºæ¶ˆæ¯åˆ—è¡¨ï¼Œåªæœ‰system_promptä¸ä¸ºç©ºæ—¶æ‰æ·»åŠ systemæ¶ˆæ¯
        messages = []
        if system_prompt and system_prompt.strip():
            messages.append({"role": "system", "content": system_prompt})
        messages.append({"role": "user", "content": user_prompt})
        
        payload = {
            "model": self.valves.OPENAI_MODEL,
            "messages": messages,
            "max_tokens": self.valves.OPENAI_MAX_TOKENS,
            "temperature": self.valves.OPENAI_TEMPERATURE,
            "stream": True
        }
        
        try:
            response = requests.post(
                url,
                headers=headers,
                json=payload,
                stream=True,
                timeout=self.valves.OPENAI_TIMEOUT
            )
            response.raise_for_status()
            
            collected_content = ""
            
            for line in response.iter_lines():
                if line:
                    line = line.decode('utf-8')
                    if line.startswith('data: '):
                        data = line[6:]
                        if data == '[DONE]':
                            break
                        try:
                            json_data = json.loads(data)
                            delta = json_data.get('choices', [{}])[0].get('delta', {}).get('content', '')
                            if delta:
                                collected_content += delta
                                self._add_output_tokens(delta)
                                yield delta
                        except json.JSONDecodeError:
                            pass
                            
        except Exception as e:
            error_msg = f"OpenAIæµå¼APIè°ƒç”¨é”™è¯¯: {str(e)}"
            if self.valves.DEBUG_MODE:
                print(f"âŒ {error_msg}")
            yield error_msg

    def _emit_processing(self, content: str, stage: str = "processing") -> Generator[dict, None, None]:
        """å‘é€å¤„ç†è¿‡ç¨‹å†…å®¹"""
        yield {
            'choices': [{
                'delta': {
                    'processing_content': content + '\n',
                    'processing_title': STAGE_TITLES.get(stage, "å¤„ç†ä¸­"),
                    'processing_stage': STAGE_GROUP.get(stage, "stage_group_1")
                },
                'finish_reason': None
            }]
        }

    def _get_system_prompt(self) -> str:
        """åŠ¨æ€ç”ŸæˆåŸºäºå¯ç”¨MCPå·¥å…·çš„ç³»ç»Ÿæç¤ºè¯"""
        base_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„åŒ–å­¦ä¿¡æ¯åŠ©æ‰‹ï¼Œèƒ½å¤Ÿä½¿ç”¨MCPå·¥å…·æ¥æŸ¥è¯¢åŒ–å­¦ç‰©è´¨çš„è¯¦ç»†ä¿¡æ¯ã€‚

ğŸ”§ å¯ç”¨å·¥å…·ï¼š
"""
        
        # åŠ¨æ€æ·»åŠ å·¥å…·ä¿¡æ¯
        if self.mcp_tools:
            for tool_name, tool_info in self.mcp_tools.items():
                base_prompt += f"""
å·¥å…·åç§°: {tool_name}
æè¿°: {tool_info.get('description', 'æ— æè¿°')}
æ ‡ç­¾: {', '.join(tool_info.get('tags', []))}
"""
                
                # æ·»åŠ è¾“å…¥å‚æ•°ä¿¡æ¯
                input_schema = tool_info.get('input_schema', {})
                if input_schema and 'properties' in input_schema:
                    base_prompt += "å‚æ•°:\n"
                    for param_name, param_info in input_schema['properties'].items():
                        param_type = param_info.get('type', 'unknown')
                        param_desc = param_info.get('description', 'æ— æè¿°')
                        param_required = param_name in input_schema.get('required', [])
                        required_str = " (å¿…éœ€)" if param_required else " (å¯é€‰)"
                        base_prompt += f"  - {param_name} ({param_type}){required_str}: {param_desc}\n"
                    base_prompt += "\n"
        else:
            base_prompt += "âš ï¸ å½“å‰æ²¡æœ‰å¯ç”¨çš„MCPå·¥å…·\n"
        
        base_prompt += """
ğŸ§  ä½¿ç”¨æŒ‡å—ï¼š
1. å½“ç”¨æˆ·è¯¢é—®åŒ–å­¦ç‰©è´¨ä¿¡æ¯æ—¶ï¼Œåˆ†æä»–ä»¬çš„éœ€æ±‚å¹¶é€‰æ‹©åˆé€‚çš„å·¥å…·
2. PubChemæ•°æ®åº“ä¸»è¦ä½¿ç”¨è‹±æ–‡ï¼Œå› æ­¤queryå‚æ•°åº”ä¸ºè‹±æ–‡åç§°ã€åˆ†å­å¼æˆ–SMILESå­—ç¬¦ä¸²
3. å¦‚æœç”¨æˆ·æä¾›ä¸­æ–‡åŒ–å­¦åç§°ï¼Œè¯·è½¬æ¢ä¸ºå¯¹åº”çš„è‹±æ–‡åç§°
4. ä¼˜å…ˆä½¿ç”¨è‹±æ–‡åŒ–å­¦åç§°æœç´¢ï¼ˆæ›´å‡†ç¡®ï¼‰

è½¬æ¢ç¤ºä¾‹ï¼š
- "å’–å•¡å› " â†’ "caffeine" (ä¸­æ–‡è½¬è‹±æ–‡å)
- "H2O" â†’ "H2O" (åˆ†å­å¼ä¿æŒä¸å˜)
- "CCO" â†’ "CCO" (SMILESä¿æŒä¸å˜)

ğŸ”„ å·¥å…·è°ƒç”¨æ ¼å¼ï¼š
å¦‚æœéœ€è¦è°ƒç”¨å·¥å…·ï¼Œè¯·å›å¤ï¼š
TOOL_CALL:<å·¥å…·åç§°>:<JSONå‚æ•°>

ç¤ºä¾‹ï¼š
- TOOL_CALL:search_chemical:{"query": "caffeine", "search_type": "name"}
- TOOL_CALL:search_chemical:{"query": "H2O", "search_type": "formula"}
- TOOL_CALL:search_chemical:{"query": "CCO", "search_type": "smiles"}

å¦‚æœä¸éœ€è¦å·¥å…·è°ƒç”¨ï¼Œè¯·ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜ã€‚å¯ä»¥å¤šæ¬¡è°ƒç”¨å·¥å…·è·å–æ›´å®Œæ•´çš„ä¿¡æ¯ã€‚
"""
        
        return base_prompt

    async def _process_user_message(self, user_message: str, messages: List[dict], stream_mode: bool) -> AsyncGenerator[str, None]:
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼Œæ”¯æŒå¤šè½®MCPå·¥å…·è°ƒç”¨"""
        
        # ç¡®ä¿å·¥å…·å·²åŠ è½½
        if not self.tools_loaded:
            try:
                if stream_mode:
                    for chunk in self._emit_processing("ğŸ” æ­£åœ¨å‘ç°MCPå·¥å…·...", "mcp_discovery"):
                        yield f'data: {json.dumps(chunk)}\n\n'
                else:
                    yield "ğŸ” æ­£åœ¨å‘ç°MCPå·¥å…·...\n"
                
                await self._discover_mcp_tools()
                
                discovery_info = f"âœ… å‘ç° {len(self.mcp_tools)} ä¸ªMCPå·¥å…·: {', '.join(self.mcp_tools.keys())}"
                if stream_mode:
                    for chunk in self._emit_processing(discovery_info, "mcp_discovery"):
                        yield f'data: {json.dumps(chunk)}\n\n'
                else:
                    yield discovery_info + "\n"
                    
            except Exception as e:
                error_msg = f"âŒ MCPå·¥å…·å‘ç°å¤±è´¥: {str(e)}"
                if stream_mode:
                    for chunk in self._emit_processing(error_msg, "mcp_discovery"):
                        yield f'data: {json.dumps(chunk)}\n\n'
                else:
                    yield error_msg + "\n"
                return
        
        # è·å–ç³»ç»Ÿæç¤ºè¯
        system_prompt = self._get_system_prompt()
        
        # æ„å»ºå¯¹è¯å†å²
        conversation_history = []
        if messages and len(messages) > 1:
            # å–æœ€è¿‘çš„å‡ è½®å¯¹è¯ä½œä¸ºä¸Šä¸‹æ–‡
            recent_messages = messages[-6:] if len(messages) > 6 else messages
            for msg in recent_messages:
                role = msg.get("role", "")
                content = msg.get("content", "")
                if role in ["user", "assistant"]:
                    conversation_history.append({"role": role, "content": content})
        
        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        conversation_history.append({"role": "user", "content": user_message})
        
        # æ„å»ºå®Œæ•´çš„ä¸Šä¸‹æ–‡æç¤º
        context_text = ""
        for msg in conversation_history[:-1]:  # é™¤äº†æœ€åä¸€æ¡æ¶ˆæ¯
            role = "ç”¨æˆ·" if msg["role"] == "user" else "åŠ©æ‰‹"
            context_text += f"{role}: {msg['content']}\n"
        
        full_user_prompt = f"""å†å²å¯¹è¯ä¸Šä¸‹æ–‡:
{context_text if context_text else "æ— å†å²å¯¹è¯"}

å½“å‰ç”¨æˆ·é—®é¢˜: {user_message}

è¯·æ ¹æ®ä¸Šä¸‹æ–‡å’Œå½“å‰é—®é¢˜ï¼Œå†³å®šæ˜¯å¦éœ€è¦è°ƒç”¨MCPå·¥å…·ã€‚å¦‚æœéœ€è¦ï¼Œè¯·æŒ‰ç…§æŒ‡å®šæ ¼å¼å›å¤å·¥å…·è°ƒç”¨ã€‚
å›ç­”è¦å¿ äºä¸Šä¸‹æ–‡ã€å½“å‰é—®é¢˜ã€å·¥å…·è¿”å›çš„ä¿¡æ¯ã€‚"""
        
        tool_call_count = 0
        collected_tool_results = []
        
        while tool_call_count < self.valves.MAX_TOOL_CALLS:
            # è·å–AIå“åº”
            ai_response = self._call_openai_api(system_prompt, full_user_prompt)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…· - æ”¯æŒé€šç”¨æ ¼å¼ TOOL_CALL:<å·¥å…·åç§°>:<JSONå‚æ•°>
            if ai_response.startswith("TOOL_CALL:"):
                tool_call_count += 1
                
                # è§£æå·¥å…·è°ƒç”¨
                try:
                    # å»é™¤å‰ç¼€å¹¶è§£æ
                    tool_call_str = ai_response.replace("TOOL_CALL:", "", 1)
                    
                    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå†’å·åˆ†éš”å·¥å…·åç§°å’Œå‚æ•°
                    if ":" in tool_call_str:
                        tool_name, tool_args_str = tool_call_str.split(":", 1)
                        tool_name = tool_name.strip()
                        tool_args = json.loads(tool_args_str)
                    else:
                        raise ValueError("æ— æ•ˆçš„å·¥å…·è°ƒç”¨æ ¼å¼")
                    
                    # éªŒè¯å·¥å…·æ˜¯å¦å­˜åœ¨
                    if tool_name not in self.mcp_tools:
                        error_msg = f"å·¥å…· '{tool_name}' ä¸å­˜åœ¨"
                        if stream_mode:
                            for chunk in self._emit_processing(f"âŒ {error_msg}", "tool_calling"):
                                yield f'data: {json.dumps(chunk)}\n\n'
                        else:
                            yield f"âŒ {error_msg}\n"
                        break
                    
                    # æ˜¾ç¤ºå·¥å…·è°ƒç”¨ä¿¡æ¯
                    call_info = f"ğŸ”§ æ­£åœ¨è°ƒç”¨MCPå·¥å…· '{tool_name}'ï¼ˆç¬¬{tool_call_count}æ¬¡ï¼‰..."
                    if stream_mode:
                        for chunk in self._emit_processing(call_info, "tool_calling"):
                            yield f'data: {json.dumps(chunk)}\n\n'
                    else:
                        yield call_info + "\n"
                    
                    # æ˜¾ç¤ºå·¥å…·è°ƒç”¨å‚æ•°
                    tool_info = f"ğŸ“ å·¥å…·è°ƒç”¨å‚æ•°: {json.dumps(tool_args, ensure_ascii=False)}"
                    if stream_mode:
                        for chunk in self._emit_processing(tool_info, "tool_calling"):
                            yield f'data: {json.dumps(chunk)}\n\n'
                    else:
                        yield tool_info + "\n"
                    
                    # è°ƒç”¨MCPå·¥å…·
                    tool_result = await self._execute_mcp_tool(tool_name, tool_args)
                    
                    # æ˜¾ç¤ºå·¥å…·è°ƒç”¨ç»“æœ
                    result_info = f"âœ… å·¥å…·è°ƒç”¨ç»“æœ:\n{tool_result[:500]}{'...' if len(tool_result) > 500 else ''}"
                    if stream_mode:
                        for chunk in self._emit_processing(result_info, "tool_calling"):
                            yield f'data: {json.dumps(chunk)}\n\n'
                    else:
                        yield result_info + "\n"
                    
                    # æ”¶é›†å·¥å…·ç»“æœ
                    collected_tool_results.append({
                        "tool": tool_name,
                        "call": tool_args,
                        "result": tool_result
                    })
                    
                    # æ›´æ–°å¯¹è¯ä¸Šä¸‹æ–‡ï¼ŒåŒ…å«å·¥å…·ç»“æœ
                    tool_context = f"[MCPå·¥å…·è°ƒç”¨ç»“æœ {tool_call_count}]\nå·¥å…·: {tool_name}\næŸ¥è¯¢: {tool_args}\nç»“æœ: {tool_result}\n\n"
                    full_user_prompt = f"{full_user_prompt}\n\n{tool_context}åŸºäºä»¥ä¸Šå·¥å…·è°ƒç”¨ç»“æœï¼Œè¯·ç»§ç»­å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœéœ€è¦æ›´å¤šä¿¡æ¯ï¼Œå¯ä»¥ç»§ç»­è°ƒç”¨å·¥å…·ã€‚"
                    
                    # ç»§ç»­ä¸‹ä¸€è½®ï¼Œçœ‹æ˜¯å¦éœ€è¦æ›´å¤šå·¥å…·è°ƒç”¨
                    continue
                    
                except (json.JSONDecodeError, ValueError) as e:
                    error_msg = f"å·¥å…·è°ƒç”¨æ ¼å¼é”™è¯¯: {str(e)}"
                    if stream_mode:
                        for chunk in self._emit_processing(f"âŒ {error_msg}", "tool_calling"):
                            yield f'data: {json.dumps(chunk)}\n\n'
                    else:
                        yield f"âŒ {error_msg}\n"
                    break
            else:
                # ä¸éœ€è¦å·¥å…·è°ƒç”¨ï¼Œç”Ÿæˆæœ€ç»ˆå›ç­”
                break
        
        # ç”Ÿæˆæœ€ç»ˆå›ç­”
        if collected_tool_results:
            # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ç»“æœï¼ŒåŸºäºç»“æœç”Ÿæˆå›ç­”
            final_system_prompt = "ä½ æ˜¯ä¸“ä¸šçš„åŒ–å­¦ä¿¡æ¯ä¸“å®¶ï¼Œè¯·åŸºäºæä¾›çš„MCPå·¥å…·è°ƒç”¨ç»“æœï¼Œä¸ºç”¨æˆ·æä¾›å‡†ç¡®ã€è¯¦ç»†çš„å›ç­”ã€‚"
            
            tool_summary = "åŸºäºä»¥ä¸‹MCPå·¥å…·è°ƒç”¨ç»“æœ:\n\n"
            for i, result in enumerate(collected_tool_results, 1):
                tool_name = result.get('tool', 'unknown')
                tool_call = result.get('call', {})
                tool_result = result.get('result', '')
                tool_summary += f"å·¥å…·è°ƒç”¨{i}: {tool_name}\n"
                tool_summary += f"å‚æ•°{i}: {json.dumps(tool_call, ensure_ascii=False)}\n"
                tool_summary += f"ç»“æœ{i}: {tool_result}\n\n"
            
            final_user_prompt = f"{tool_summary}ç”¨æˆ·é—®é¢˜: {user_message}\n\nè¯·åŸºäºä»¥ä¸Šå·¥å…·è°ƒç”¨ç»“æœä¸ºç”¨æˆ·æä¾›å‡†ç¡®è¯¦ç»†çš„å›ç­”ã€‚"
            
            if stream_mode:
                # æµå¼æ¨¡å¼å¼€å§‹ç”Ÿæˆå›ç­”çš„æ ‡è¯†
                answer_start_msg = {
                    'choices': [{
                        'delta': {
                            'content': "\n**ğŸ§ª åŸºäºMCPå·¥å…·è°ƒç”¨ç»“æœå›ç­”**\n"
                        },
                        'finish_reason': None
                    }]
                }
                yield f"data: {json.dumps(answer_start_msg)}\n\n"
                
                # æµå¼ç”Ÿæˆæœ€ç»ˆå›ç­”
                for chunk in self._stream_openai_response(final_user_prompt, final_system_prompt):
                    # åŒ…è£…æˆSSEæ ¼å¼
                    chunk_data = {
                        'choices': [{
                            'delta': {
                                'content': chunk
                            },
                            'finish_reason': None
                        }]
                    }
                    yield f"data: {json.dumps(chunk_data)}\n\n"
            else:
                yield "ğŸ§ª **åŸºäºMCPå·¥å…·è°ƒç”¨ç»“æœå›ç­”**\n"
                final_answer = self._call_openai_api(final_system_prompt, final_user_prompt)
                yield final_answer
        else:
            # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å›AIå“åº”
            if stream_mode:
                # æµå¼æ¨¡å¼
                answer_start_msg = {
                    'choices': [{
                        'delta': {
                            'content': "\n**ğŸ’­ å›ç­”**\n"
                        },
                        'finish_reason': None
                    }]
                }
                yield f"data: {json.dumps(answer_start_msg)}\n\n"
                
                for chunk in self._stream_openai_response(full_user_prompt, system_prompt):
                    chunk_data = {
                        'choices': [{
                            'delta': {
                                'content': chunk
                            },
                            'finish_reason': None
                        }]
                    }
                    yield f"data: {json.dumps(chunk_data)}\n\n"
            else:
                yield "ğŸ’­ **å›ç­”**\n"
                yield ai_response

    def pipe(self, user_message: str, model_id: str, messages: List[dict], body: dict) -> Union[str, Generator, Iterator]:
        """ä¸»ç®¡é“å‡½æ•°"""
        # é‡ç½®tokenç»Ÿè®¡
        self._reset_token_stats()

        if self.valves.DEBUG_MODE:
            print(f"ğŸ§ª MCPåŒ–å­¦åŠ©æ‰‹V2æ”¶åˆ°æ¶ˆæ¯: {user_message}")
            print(f"ğŸ”§ æ¨¡å‹ID: {model_id}")
            print(f"ğŸ“œ å†å²æ¶ˆæ¯æ•°é‡: {len(messages) if messages else 0}")
            print(f"ğŸ”— MCPæœåŠ¡å™¨: {self.valves.MCP_SERVER_URL}")
            print(f"ğŸ·ï¸ MCPæ ‡ç­¾: {self.valves.MCP_TAG}")

        # éªŒè¯è¾“å…¥
        if not user_message or not user_message.strip():
            yield "âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„åŒ–å­¦é—®é¢˜æˆ–æŸ¥è¯¢å†…å®¹"
            return

        # æ£€æŸ¥æ˜¯å¦æ˜¯æµå¼æ¨¡å¼  
        stream_mode = body.get("stream", False) and self.valves.ENABLE_STREAMING
        
        try:
            # MCPæœåŠ¡å‘ç°é˜¶æ®µ
            if stream_mode:
                for chunk in self._emit_processing("ğŸ” æ­£åœ¨å‡†å¤‡MCPæœåŠ¡...", "mcp_discovery"):
                    yield f'data: {json.dumps(chunk)}\n\n'
            else:
                yield "ğŸ” **é˜¶æ®µ1**: æ­£åœ¨å‡†å¤‡MCPæœåŠ¡...\n"
            
            # åœ¨åŒæ­¥ç¯å¢ƒä¸­è¿è¡Œå¼‚æ­¥ä»£ç 
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                # å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼Œå¯èƒ½åŒ…å«å¤šæ¬¡å·¥å…·è°ƒç”¨
                async def run_process():
                    results = []
                    async for result in self._process_user_message(user_message, messages, stream_mode):
                        results.append(result)
                    return results
                
                # è·å–æ‰€æœ‰ç»“æœå¹¶é€ä¸ªyield
                results = loop.run_until_complete(run_process())
                for result in results:
                    yield result
                
                # æœ€åå‘é€å®Œæˆä¿¡æ¯
                if stream_mode:
                    # æµå¼æ¨¡å¼ç»“æŸ
                    done_msg = {
                        'choices': [{
                            'delta': {},
                            'finish_reason': 'stop'
                        }]
                    }
                    yield f"data: {json.dumps(done_msg)}\n\n"
                    yield "data: [DONE]\n\n"
                    
                    # æ·»åŠ tokenç»Ÿè®¡
                    token_info = self._get_token_stats()
                    token_msg = {
                        'choices': [{
                            'delta': {
                                'content': f"\n\n---\nğŸ“Š **Tokenç»Ÿè®¡**: è¾“å…¥ {token_info['input_tokens']}, è¾“å‡º {token_info['output_tokens']}, æ€»è®¡ {token_info['total_tokens']}"
                            },
                            'finish_reason': None
                        }]
                    }
                    yield f"data: {json.dumps(token_msg)}\n\n"
                else:
                    # æ·»åŠ tokenç»Ÿè®¡ä¿¡æ¯
                    token_info = self._get_token_stats()
                    yield f"\n\n---\nğŸ“Š **Tokenç»Ÿè®¡**: è¾“å…¥ {token_info['input_tokens']}, è¾“å‡º {token_info['output_tokens']}, æ€»è®¡ {token_info['total_tokens']}"
                    
            finally:
                loop.close()

        except Exception as e:
            error_msg = f"âŒ Pipelineæ‰§è¡Œé”™è¯¯: {str(e)}"
            if self.valves.DEBUG_MODE:
                print(f"âŒ {error_msg}")
            
            if stream_mode:
                error_chunk = {
                    'choices': [{
                        'delta': {
                            'content': error_msg
                        },
                        'finish_reason': 'stop'
                    }]
                }
                yield f"data: {json.dumps(error_chunk)}\n\n"
                yield "data: [DONE]\n\n"
            else:
                yield error_msg